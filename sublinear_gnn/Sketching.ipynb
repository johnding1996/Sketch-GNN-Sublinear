{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c22345-eb93-4b06-890d-e64f738250f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "from torch_sparse.tensor import SparseTensor\n",
    "\n",
    "from sketch import CountSketch, TensorSketch\n",
    "from sketch import Backends, OutputTypes, SketchConfig, DEFAULT_COUNT_SKETCH_CONFIG, DEFAULT_TENSOR_SKETCH_CONFIG\n",
    "from initialize_sketch import initialize_single_layer_sketch_modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc407ab-cb4d-4dff-8721-201488b2eeb6",
   "metadata": {},
   "source": [
    "## Validate and Benchmark Count-Sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4572a9dc-e55f-463d-95ef-d0753cc9ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = ['dense_CPU', 'dense_GPU', 'sparse_CPU', 'sparse_GPU']\n",
    "backends = [Backends.PYTORCH, Backends.PYTORCH_SPARSE, Backends.PYG_SPARSE, Backends.PYG_SCATTER]\n",
    "\n",
    "in_dim = 2048\n",
    "out_dim = 128\n",
    "feature_dim = 128\n",
    "repeats = 128\n",
    "log_interval = 32\n",
    "ntrials = 3\n",
    "max_degree = 3\n",
    "avg_node_degree = 64\n",
    "\n",
    "row = torch.arange(in_dim, dtype=torch.int64).repeat_interleave(avg_node_degree)\n",
    "u0_col = torch.from_numpy(np.concatenate([np.random.choice(feature_dim, avg_node_degree, replace=False) for _ in range(in_dim)], axis=0, dtype=np.int64))\n",
    "u0_val = torch.rand(avg_node_degree*in_dim, dtype=torch.float32)\n",
    "u0_s = SparseTensor(row=row, col=u0_col, value=u0_val, sparse_sizes=(in_dim, feature_dim), is_sorted=False)\n",
    "v0_col = torch.from_numpy(np.concatenate([np.random.choice(feature_dim, avg_node_degree, replace=False) for _ in range(in_dim)], axis=0, dtype=np.int64))\n",
    "v0_val = torch.rand(avg_node_degree*in_dim, dtype=torch.float32)\n",
    "v0_s = SparseTensor(row=row, col=v0_col, value=v0_val, sparse_sizes=(in_dim, feature_dim), is_sorted=False)\n",
    "u0_d = u0_s.to_dense()\n",
    "v0_d = v0_s.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dfede2c-e601-4f22-885b-7d4f524847b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConutSketch:\n",
      "Mode: dense_CPU, Backend: Backends.PYTORCH\n",
      "# of repeats: 032,              relative error: 23.48+/-0.26%\n",
      "# of repeats: 064,              relative error: 12.35+/-0.49%\n",
      "# of repeats: 096,              relative error: 8.45+/-0.49%\n",
      "# of repeats: 128,              relative error: 6.41+/-0.59%\n",
      "output density: 99.97%\n",
      "Mode: dense_CPU, Backend: Backends.PYTORCH_SPARSE\n",
      "# of repeats: 032,              relative error: 22.17+/-0.85%\n",
      "# of repeats: 064,              relative error: 11.32+/-0.54%\n",
      "# of repeats: 096,              relative error: 7.80+/-0.35%\n",
      "# of repeats: 128,              relative error: 6.06+/-0.39%\n",
      "output density: 99.97%\n",
      "Mode: dense_CPU, Backend: Backends.PYG_SPARSE\n",
      "# of repeats: 032,              relative error: 22.75+/-1.05%\n",
      "# of repeats: 064,              relative error: 11.83+/-0.81%\n",
      "# of repeats: 096,              relative error: 7.96+/-0.70%\n",
      "# of repeats: 128,              relative error: 5.97+/-0.76%\n",
      "output density: 99.97%\n",
      "Mode: dense_CPU, Backend: Backends.PYG_SCATTER\n",
      "# of repeats: 032,              relative error: 22.05+/-0.38%\n",
      "# of repeats: 064,              relative error: 11.54+/-0.86%\n",
      "# of repeats: 096,              relative error: 7.78+/-0.68%\n",
      "# of repeats: 128,              relative error: 5.88+/-0.29%\n",
      "output density: 99.97%\n",
      "Mode: dense_GPU, Backend: Backends.PYTORCH\n",
      "# of repeats: 032,              relative error: 21.44+/-0.20%\n",
      "# of repeats: 064,              relative error: 11.15+/-0.17%\n",
      "# of repeats: 096,              relative error: 7.67+/-0.43%\n",
      "# of repeats: 128,              relative error: 5.66+/-0.43%\n",
      "output density: 99.97%\n",
      "Mode: dense_GPU, Backend: Backends.PYTORCH_SPARSE\n",
      "# of repeats: 032,              relative error: 22.13+/-0.25%\n",
      "# of repeats: 064,              relative error: 11.46+/-0.47%\n",
      "# of repeats: 096,              relative error: 7.79+/-0.50%\n",
      "# of repeats: 128,              relative error: 5.88+/-0.42%\n",
      "output density: 99.97%\n",
      "Mode: dense_GPU, Backend: Backends.PYG_SPARSE\n",
      "# of repeats: 032,              relative error: 22.59+/-0.80%\n",
      "# of repeats: 064,              relative error: 12.07+/-0.71%\n",
      "# of repeats: 096,              relative error: 8.07+/-0.51%\n",
      "# of repeats: 128,              relative error: 6.15+/-0.22%\n",
      "output density: 99.97%\n",
      "Mode: dense_GPU, Backend: Backends.PYG_SCATTER\n",
      "# of repeats: 032,              relative error: 23.11+/-0.31%\n",
      "# of repeats: 064,              relative error: 11.87+/-0.29%\n",
      "# of repeats: 096,              relative error: 7.72+/-0.13%\n",
      "# of repeats: 128,              relative error: 5.97+/-0.28%\n",
      "output density: 99.97%\n",
      "Mode: sparse_CPU, Backend: Backends.PYTORCH\n",
      "Not Implemented\n",
      "Mode: sparse_CPU, Backend: Backends.PYTORCH_SPARSE\n",
      "# of repeats: 032,              relative error: 22.52+/-1.35%\n",
      "# of repeats: 064,              relative error: 11.73+/-0.57%\n",
      "# of repeats: 096,              relative error: 8.03+/-0.32%\n",
      "# of repeats: 128,              relative error: 6.27+/-0.20%\n",
      "output density: 99.97%\n",
      "Mode: sparse_CPU, Backend: Backends.PYG_SPARSE\n",
      "# of repeats: 032,              relative error: 21.79+/-0.97%\n",
      "# of repeats: 064,              relative error: 11.61+/-0.20%\n",
      "# of repeats: 096,              relative error: 7.76+/-0.34%\n",
      "# of repeats: 128,              relative error: 6.08+/-0.37%\n",
      "output density: 99.97%\n",
      "Mode: sparse_CPU, Backend: Backends.PYG_SCATTER\n",
      "Not Implemented\n",
      "Mode: sparse_GPU, Backend: Backends.PYTORCH\n",
      "Not Implemented\n",
      "Mode: sparse_GPU, Backend: Backends.PYTORCH_SPARSE\n",
      "# of repeats: 032,              relative error: 21.64+/-0.36%\n",
      "# of repeats: 064,              relative error: 11.78+/-0.29%\n",
      "# of repeats: 096,              relative error: 8.02+/-0.39%\n",
      "# of repeats: 128,              relative error: 5.99+/-0.37%\n",
      "output density: 99.97%\n",
      "Mode: sparse_GPU, Backend: Backends.PYG_SPARSE\n",
      "# of repeats: 032,              relative error: 22.36+/-0.82%\n",
      "# of repeats: 064,              relative error: 12.08+/-0.21%\n",
      "# of repeats: 096,              relative error: 8.39+/-0.49%\n",
      "# of repeats: 128,              relative error: 6.43+/-0.41%\n",
      "output density: 99.97%\n",
      "Mode: sparse_GPU, Backend: Backends.PYG_SCATTER\n",
      "Not Implemented\n"
     ]
    }
   ],
   "source": [
    "def validate_count_sketch(x0, config):\n",
    "    device = x0.device if isinstance(x0, torch.Tensor) else x0.device()\n",
    "    rel_errors = np.zeros((repeats//log_interval, ntrials))\n",
    "    density = 0\n",
    "    for t in range(ntrials):\n",
    "        if isinstance(x0, torch.Tensor):\n",
    "            usx0 = torch.zeros_like(x0).to(device)\n",
    "        else:\n",
    "            usx0 = torch.zeros((in_dim, feature_dim), dtype=torch.float32).to(device)\n",
    "        for r in range(1, repeats+1):\n",
    "            count_sketch = CountSketch(in_dim, out_dim, config).to(device)\n",
    "            _csx0 = count_sketch(x0)\n",
    "            csx0 = _csx0 if isinstance(_csx0, torch.Tensor) else _csx0.to_dense()\n",
    "            density += torch.count_nonzero(csx0)/out_dim/feature_dim\n",
    "            _usx0 = count_sketch.unsketch_mat(_csx0)\n",
    "            usx0 += _usx0 if isinstance(_usx0, torch.Tensor) else _usx0.to_dense()\n",
    "            x0_norm = torch.norm(x0 if isinstance(x0, torch.Tensor) else x0.to_dense(), dim=0)\n",
    "            if r % log_interval == 0:\n",
    "                rel_errors[r//log_interval-1, t] = (torch.sum(torch.abs(x0_norm-torch.norm(usx0/r, dim=0)))/\n",
    "                                                    torch.sum(x0_norm)).cpu().numpy()\n",
    "    for i in range(repeats//log_interval):\n",
    "        avg_rel_error = np.mean(rel_errors, axis=1)\n",
    "        std_rel_error = np.std(rel_errors, axis=1)\n",
    "        print(f\"# of repeats: {log_interval*(i+1):03d},\\\n",
    "              relative error: {avg_rel_error[i]*100:.2f}+/-{std_rel_error[i]*100:.2f}%\")\n",
    "    print(f\"output density: {density/ntrials/repeats*100:.2f}%\")\n",
    "\n",
    "print(\"ConutSketch:\")\n",
    "for mode in modes:\n",
    "    for backend in backends:\n",
    "        config = copy.copy(DEFAULT_COUNT_SKETCH_CONFIG)\n",
    "        setattr(config, mode, backend)\n",
    "        print(f\"Mode: {mode}, Backend: {backend}\")\n",
    "        if mode.startswith('dense'):\n",
    "            x0 = u0_d\n",
    "        else:\n",
    "            x0 = u0_s\n",
    "        if mode.endswith('CPU'):\n",
    "            x0 = x0.cpu()\n",
    "        else:\n",
    "            x0 = x0.cuda()\n",
    "        try:\n",
    "            validate_count_sketch(x0, config)\n",
    "        except NotImplementedError as e:\n",
    "            print('Not Implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73a4c65e-0510-466e-ac1f-e88cc6d9bf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConutSketch:\n",
      "Mode: dense_CPU, Backend: Backends.PYTORCH\n",
      "Unit time: 1.61 ms ± 145 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "Mode: dense_CPU, Backend: Backends.PYTORCH_SPARSE\n",
      "Unit time: 1.01 ms ± 160 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "Mode: dense_CPU, Backend: Backends.PYG_SPARSE\n",
      "Unit time: The slowest run took 8.77 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "2.32 ms ± 2.16 ms per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "Mode: dense_CPU, Backend: Backends.PYG_SCATTER\n",
      "Unit time: 1.28 ms ± 87.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "Mode: dense_GPU, Backend: Backends.PYTORCH\n",
      "Unit time: 43.1 µs ± 455 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "Mode: dense_GPU, Backend: Backends.PYTORCH_SPARSE\n",
      "Unit time: 507 µs ± 20.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "Mode: dense_GPU, Backend: Backends.PYG_SPARSE\n",
      "Unit time: 50.9 µs ± 4.89 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "Mode: dense_GPU, Backend: Backends.PYG_SCATTER\n",
      "Unit time: 71.8 µs ± 11.9 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "Mode: sparse_CPU, Backend: Backends.PYTORCH\n",
      "Not Implemented\n",
      "Mode: sparse_CPU, Backend: Backends.PYTORCH_SPARSE\n",
      "Unit time: 22.6 ms ± 1.89 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Mode: sparse_CPU, Backend: Backends.PYG_SPARSE\n",
      "Unit time: 2.6 ms ± 646 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Mode: sparse_CPU, Backend: Backends.PYG_SCATTER\n",
      "Not Implemented\n",
      "Mode: sparse_GPU, Backend: Backends.PYTORCH\n",
      "Not Implemented\n",
      "Mode: sparse_GPU, Backend: Backends.PYTORCH_SPARSE\n",
      "Unit time: 4.75 ms ± 490 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Mode: sparse_GPU, Backend: Backends.PYG_SPARSE\n",
      "Unit time: 9.99 ms ± 1.14 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Mode: sparse_GPU, Backend: Backends.PYG_SCATTER\n",
      "Not Implemented\n"
     ]
    }
   ],
   "source": [
    "print(\"ConutSketch:\")\n",
    "for mode in modes:\n",
    "    for backend in backends:\n",
    "        config = copy.copy(DEFAULT_COUNT_SKETCH_CONFIG)\n",
    "        setattr(config, mode, backend)\n",
    "        print(f\"Mode: {mode}, Backend: {backend}\")\n",
    "        if mode.startswith('dense'):\n",
    "            x0 = u0_d\n",
    "        else:\n",
    "            x0 = u0_s\n",
    "        if mode.endswith('CPU'):\n",
    "            x0 = x0.cpu()\n",
    "            count_sketch = CountSketch(in_dim, out_dim, config).cpu()\n",
    "        else:\n",
    "            x0 = x0.cuda()\n",
    "            count_sketch = CountSketch(in_dim, out_dim, config).cuda()\n",
    "        try:\n",
    "            count_sketch(x0)\n",
    "            print(\"Unit time: \", end=\"\")\n",
    "            %timeit count_sketch(x0)\n",
    "        except NotImplementedError as e:\n",
    "            print('Not Implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2c45fad-6760-4de0-804f-a43ac3c681fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConutSketch:\n",
      "Backend: Backends.PYTORCH\n",
      "Module memory: 1.1796875 MB\n",
      "Backend: Backends.PYTORCH_SPARSE\n",
      "Module memory: 0.1796875 MB\n",
      "Backend: Backends.PYG_SPARSE\n",
      "Module memory: 0.1796875 MB\n",
      "Backend: Backends.PYG_SCATTER\n",
      "Module memory: 0.1953125 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"ConutSketch:\")\n",
    "for backend in backends:\n",
    "    config = copy.copy(DEFAULT_COUNT_SKETCH_CONFIG)\n",
    "    setattr(config, 'dense_GPU', backend)\n",
    "    print(f\"Backend: {backend}\")\n",
    "    try:\n",
    "        torch.cuda.empty_cache()\n",
    "        count_sketch = CountSketch(in_dim, out_dim, config).cuda()\n",
    "        mem_before = torch.cuda.memory_allocated(0)\n",
    "        del count_sketch\n",
    "        torch.cuda.empty_cache()\n",
    "        mem_after = torch.cuda.memory_allocated(0)\n",
    "        print(f\"Module memory: {(mem_before - mem_after)/1048576.0} MB\")\n",
    "    except NotImplementedError as e:\n",
    "        print('Not Implemented')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bd9101-03f3-4bf0-9b54-bf74b46f1c15",
   "metadata": {},
   "source": [
    "### Backends\n",
    "\n",
    "We test the sketching unit time with three types of inputs:\n",
    "\n",
    "1. Sparse suqare matrix: 2048x2048, density=0.78%\n",
    "\n",
    "```\n",
    "ConutSketch:\n",
    "Mode: dense_CPU, Backend: Backends.PYTORCH\n",
    "Unit time: 11.4 ms ± 174 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "Mode: dense_CPU, Backend: Backends.PYTORCH_SPARSE\n",
    "Unit time: 4.7 ms ± 420 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "Mode: dense_CPU, Backend: Backends.PYG_SPARSE\n",
    "Unit time: 5.18 ms ± 211 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "Mode: dense_CPU, Backend: Backends.PYG_SCATTER\n",
    "Unit time: 18.2 ms ± 66.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "Mode: dense_GPU, Backend: Backends.PYTORCH\n",
    "Unit time: 166 µs ± 1.17 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
    "Mode: dense_GPU, Backend: Backends.PYTORCH_SPARSE\n",
    "Unit time: 589 µs ± 3.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "Mode: dense_GPU, Backend: Backends.PYG_SPARSE\n",
    "Unit time: 120 µs ± 481 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
    "Mode: dense_GPU, Backend: Backends.PYG_SCATTER\n",
    "Unit time: 118 µs ± 481 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
    "Mode: sparse_CPU, Backend: Backends.PYTORCH\n",
    "Not Implemented\n",
    "Mode: sparse_CPU, Backend: Backends.PYTORCH_SPARSE\n",
    "Unit time: 5.62 ms ± 242 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "Mode: sparse_CPU, Backend: Backends.PYG_SPARSE\n",
    "Unit time: 1.16 ms ± 22.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "Mode: sparse_CPU, Backend: Backends.PYG_SCATTER\n",
    "Not Implemented\n",
    "Mode: sparse_GPU, Backend: Backends.PYTORCH\n",
    "Not Implemented\n",
    "Mode: sparse_GPU, Backend: Backends.PYTORCH_SPARSE\n",
    "Unit time: 2.66 ms ± 57.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "Mode: sparse_GPU, Backend: Backends.PYG_SPARSE\n",
    "Unit time: 6.79 ms ± 25.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "Mode: sparse_GPU, Backend: Backends.PYG_SCATTER\n",
    "Not Implemented\n",
    "```\n",
    "\n",
    "2. Dense tall matrix: 2048x128, density=87.5%\n",
    "\n",
    "```\n",
    "ConutSketch:\n",
    "Mode: dense_CPU, Backend: Backends.PYTORCH\n",
    "Unit time: 884 µs ± 11.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "Mode: dense_CPU, Backend: Backends.PYTORCH_SPARSE\n",
    "Unit time: 557 µs ± 19.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "Mode: dense_CPU, Backend: Backends.PYG_SPARSE\n",
    "Unit time: 603 µs ± 8.89 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "Mode: dense_CPU, Backend: Backends.PYG_SCATTER\n",
    "Unit time: 923 µs ± 22.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "Mode: dense_GPU, Backend: Backends.PYTORCH\n",
    "Unit time: 41.8 µs ± 135 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
    "Mode: dense_GPU, Backend: Backends.PYTORCH_SPARSE\n",
    "Unit time: 492 µs ± 28.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "Mode: dense_GPU, Backend: Backends.PYG_SPARSE\n",
    "Unit time: 43.4 µs ± 243 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
    "Mode: dense_GPU, Backend: Backends.PYG_SCATTER\n",
    "Unit time: 45.3 µs ± 114 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
    "Mode: sparse_CPU, Backend: Backends.PYTORCH\n",
    "Not Implemented\n",
    "Mode: sparse_CPU, Backend: Backends.PYTORCH_SPARSE\n",
    "Unit time: 19.5 ms ± 600 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "Mode: sparse_CPU, Backend: Backends.PYG_SPARSE\n",
    "Unit time: 1.15 ms ± 20.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "Mode: sparse_CPU, Backend: Backends.PYG_SCATTER\n",
    "Not Implemented\n",
    "Mode: sparse_GPU, Backend: Backends.PYTORCH\n",
    "Not Implemented\n",
    "Mode: sparse_GPU, Backend: Backends.PYTORCH_SPARSE\n",
    "Unit time: 2.93 ms ± 37.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "Mode: sparse_GPU, Backend: Backends.PYG_SPARSE\n",
    "Unit time: 5.73 ms ± 105 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "Mode: sparse_GPU, Backend: Backends.PYG_SCATTER\n",
    "Not Implemented\n",
    "```\n",
    "\n",
    "3. Sparse tall matrix: 2048x128, density=12.5%\n",
    "\n",
    "```\n",
    "ConutSketch:\n",
    "Mode: dense_CPU, Backend: Backends.PYTORCH\n",
    "Unit time: 880 µs ± 5.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "Mode: dense_CPU, Backend: Backends.PYTORCH_SPARSE\n",
    "Unit time: 542 µs ± 8.19 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "Mode: dense_CPU, Backend: Backends.PYG_SPARSE\n",
    "Unit time: 607 µs ± 5.65 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "Mode: dense_CPU, Backend: Backends.PYG_SCATTER\n",
    "Unit time: 897 µs ± 11 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "Mode: dense_GPU, Backend: Backends.PYTORCH\n",
    "Unit time: 42.1 µs ± 167 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
    "Mode: dense_GPU, Backend: Backends.PYTORCH_SPARSE\n",
    "Unit time: 497 µs ± 26.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "Mode: dense_GPU, Backend: Backends.PYG_SPARSE\n",
    "Unit time: 43.3 µs ± 117 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
    "Mode: dense_GPU, Backend: Backends.PYG_SCATTER\n",
    "Unit time: 45.1 µs ± 92.2 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
    "Mode: sparse_CPU, Backend: Backends.PYTORCH\n",
    "Not Implemented\n",
    "Mode: sparse_CPU, Backend: Backends.PYTORCH_SPARSE\n",
    "Unit time: 3.85 ms ± 117 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "Mode: sparse_CPU, Backend: Backends.PYG_SPARSE\n",
    "Unit time: 569 µs ± 18.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "Mode: sparse_CPU, Backend: Backends.PYG_SCATTER\n",
    "Not Implemented\n",
    "Mode: sparse_GPU, Backend: Backends.PYTORCH\n",
    "Not Implemented\n",
    "Mode: sparse_GPU, Backend: Backends.PYTORCH_SPARSE\n",
    "Unit time: 2.56 ms ± 72 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "Mode: sparse_GPU, Backend: Backends.PYG_SPARSE\n",
    "Unit time: 6.75 ms ± 73.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "Mode: sparse_GPU, Backend: Backends.PYG_SCATTER\n",
    "Not Implemented\n",
    "```\n",
    "\n",
    "The conclusion on backend selection is the same, which is:\n",
    "\n",
    "```\n",
    "DEFAULT_COUNT_SKETCH_CONFIG = SketchConfig(\n",
    "    dense_CPU=Backends.PYTORCH_SPARSE,\n",
    "    dense_GPU=Backends.PYG_SPARSE,\n",
    "    sparse_CPU=Backends.PYG_SPARSE,\n",
    "    sparse_GPU=Backends.PYTORCH_SPARSE\n",
    ")\n",
    "```\n",
    "\n",
    "### Sparse or Dense Output\n",
    "\n",
    "Comparing the last two bulk timing results. We find that if memory allows, using dense representation is always faster. However, if the output is indeed sparse (density smaller than a threshold), we should keep the sparse representation even if it cost more time in preprocessing. Another option is to always use dense representation output, and convert to sparse representation if at the end if it is indeed sparse.\n",
    "\n",
    "For simplicity, we can stick to use dense representation output here, no matter whether the final sketched matrix will be indeed sparse or not. This will also greatly reduce the number of possible backends of TensorSketch at this time. Later, we can further optimize this part by discussing when the intermediate output is sparse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb71470-a829-49f8-ad22-b247f385cb0c",
   "metadata": {},
   "source": [
    "## Validate and Benchmark Tensor-Sketch\n",
    "\n",
    "### Input\n",
    "\n",
    "For TensorSketch, we only care the case when the input is a large square sparse matrix. We can use 2048x2048, density=0.78% as a test case.\n",
    "\n",
    "### Backends\n",
    "\n",
    "Two types of backends are considered: FFT-based (which reply on the implementation of CountSketch) or TensorSketch-based. Theoretically FFT-based is faster for degree>=2, however practically there is a chance that they are still comparable when degree<=3.\n",
    "\n",
    "FFT-based backends are of high priority. We can use FFT even for sparse inputs, only need to convert to dense matrix before FFT and IFFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "977ae06a-e779-4ca0-979c-388be93f7668",
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = ['sparse_CPU', 'sparse_GPU']\n",
    "backends = [Backends.PYTORCH_FFT]\n",
    "\n",
    "in_dim = 2048\n",
    "out_dim = 512\n",
    "feature_dim = in_dim\n",
    "repeats = 128\n",
    "log_interval = 32\n",
    "ntrials = 3\n",
    "max_degree = 3\n",
    "avg_node_degree = 16\n",
    "\n",
    "row = torch.arange(in_dim, dtype=torch.int64).repeat_interleave(avg_node_degree)\n",
    "u0_col = torch.from_numpy(np.concatenate([np.random.choice(feature_dim, avg_node_degree, replace=False) for _ in range(in_dim)], axis=0, dtype=np.int64))\n",
    "u0_val = torch.rand(avg_node_degree*in_dim, dtype=torch.float32)\n",
    "u0_s = SparseTensor(row=row, col=u0_col, value=u0_val, sparse_sizes=(in_dim, feature_dim), is_sorted=False)\n",
    "v0_col = torch.from_numpy(np.concatenate([np.random.choice(feature_dim, avg_node_degree, replace=False) for _ in range(in_dim)], axis=0, dtype=np.int64))\n",
    "v0_val = torch.rand(avg_node_degree*in_dim, dtype=torch.float32)\n",
    "v0_s = SparseTensor(row=row, col=v0_col, value=v0_val, sparse_sizes=(in_dim, feature_dim), is_sorted=False)\n",
    "u0_d = u0_s.to_dense()\n",
    "v0_d = v0_s.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42890123-527f-4c7e-b3c0-58b5b199b413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorSketch: degree = 2\n",
      "Mode: sparse_CPU, Backend: Backends.PYTORCH_FFT\n",
      "# of repeats: 032,              relative error: 301.85+/-0.11%\n",
      "# of repeats: 064,              relative error: 213.53+/-0.09%\n",
      "# of repeats: 096,              relative error: 174.38+/-0.06%\n",
      "# of repeats: 128,              relative error: 150.99+/-0.06%\n",
      "output density: 96.33%\n",
      "Mode: sparse_GPU, Backend: Backends.PYTORCH_FFT\n",
      "# of repeats: 032,              relative error: 301.93+/-0.03%\n",
      "# of repeats: 064,              relative error: 213.44+/-0.04%\n",
      "# of repeats: 096,              relative error: 174.24+/-0.13%\n",
      "# of repeats: 128,              relative error: 150.90+/-0.09%\n",
      "output density: 97.60%\n",
      "TensorSketch: degree = 3\n",
      "Mode: sparse_CPU, Backend: Backends.PYTORCH_FFT\n",
      "# of repeats: 032,              relative error: 2193.01+/-1.03%\n",
      "# of repeats: 064,              relative error: 1549.76+/-0.82%\n",
      "# of repeats: 096,              relative error: 1265.26+/-1.08%\n",
      "# of repeats: 128,              relative error: 1096.36+/-0.76%\n",
      "output density: 99.81%\n",
      "Mode: sparse_GPU, Backend: Backends.PYTORCH_FFT\n",
      "# of repeats: 032,              relative error: 2194.21+/-2.65%\n",
      "# of repeats: 064,              relative error: 1552.01+/-0.65%\n",
      "# of repeats: 096,              relative error: 1267.22+/-0.30%\n",
      "# of repeats: 128,              relative error: 1097.11+/-0.43%\n",
      "output density: 99.87%\n"
     ]
    }
   ],
   "source": [
    "def validate_tensor_sketch(x0, y0, degree, config):\n",
    "    device = x0.device if isinstance(x0, torch.Tensor) else x0.device()\n",
    "    _prod = x0.t() @ y0\n",
    "    prod = _prod if isinstance(_prod, torch.Tensor) else _prod.to_dense()\n",
    "    pow_prod = torch.pow(prod, degree)\n",
    "    rel_errors = np.zeros((repeats//log_interval, ntrials))\n",
    "    density = 0\n",
    "    for t in range(ntrials):\n",
    "        app_pow_prod = torch.zeros(feature_dim, feature_dim).to(device)\n",
    "        for r in range(1, repeats+1):\n",
    "            tensor_sketch = initialize_single_layer_sketch_modules(in_dim, out_dim, degree, tensor_sketch_config=config)[1].to(device)\n",
    "            _tsx0 = tensor_sketch(x0)[-1]\n",
    "            _tsy0 = tensor_sketch(y0)[-1]\n",
    "            app_pow_prod += _tsx0.T @ _tsy0\n",
    "            tsx0 = _tsx0 if isinstance(_tsx0, torch.Tensor) else _tsx0.to_dense()\n",
    "            density += torch.count_nonzero(tsx0)/out_dim/feature_dim\n",
    "            if r % log_interval == 0:\n",
    "                rel_errors[r//log_interval-1, t] = (torch.norm(pow_prod-app_pow_prod/r)/torch.norm(pow_prod)).cpu().numpy()\n",
    "    for i in range(repeats//log_interval):\n",
    "        avg_rel_error = np.mean(rel_errors, axis=1)\n",
    "        std_rel_error = np.std(rel_errors, axis=1)\n",
    "        print(f\"# of repeats: {log_interval*(i+1):03d},\\\n",
    "              relative error: {avg_rel_error[i]*100:.2f}+/-{std_rel_error[i]*100:.2f}%\")\n",
    "    print(f\"output density: {density/ntrials/repeats*100:.2f}%\")\n",
    "\n",
    "\n",
    "for degree in range(2, max_degree+1):\n",
    "    print(f\"TensorSketch: degree = {degree}\")\n",
    "    for mode in modes:\n",
    "        for backend in backends:\n",
    "            config = copy.copy(DEFAULT_TENSOR_SKETCH_CONFIG)\n",
    "            setattr(config, mode, backend)\n",
    "            print(f\"Mode: {mode}, Backend: {backend}\")\n",
    "            if mode.startswith('dense'):\n",
    "                x0, y0 = u0_d, v0_d\n",
    "            else:\n",
    "                x0, y0 = u0_s, v0_s\n",
    "            if mode.endswith('CPU'):\n",
    "                x0, y0 = x0.cpu(), y0.cpu()\n",
    "            else:\n",
    "                x0, y0 = x0.cuda(), y0.cuda()\n",
    "            #try:\n",
    "            validate_tensor_sketch(x0, y0, degree, config)\n",
    "            #except NotImplementedError as e:\n",
    "            #    print('Not Implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4113fac2-6a6d-447d-8974-2fe4084612b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorSketch: degree = 2\n",
      "Mode: sparse_CPU, Backend: Backends.PYTORCH_FFT\n",
      "Unit time: 18.6 ms ± 531 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Mode: sparse_GPU, Backend: Backends.PYTORCH_FFT\n",
      "Unit time: 8.46 ms ± 701 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "TensorSketch: degree = 3\n",
      "Mode: sparse_CPU, Backend: Backends.PYTORCH_FFT\n",
      "Unit time: 24.3 ms ± 763 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Mode: sparse_GPU, Backend: Backends.PYTORCH_FFT\n",
      "Unit time: 9.01 ms ± 218 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "for degree in range(2, max_degree+1):\n",
    "    print(f\"TensorSketch: degree = {degree}\")\n",
    "    for mode in modes:\n",
    "        for backend in backends:\n",
    "            config = copy.copy(DEFAULT_TENSOR_SKETCH_CONFIG)\n",
    "            setattr(config, mode, backend)\n",
    "            print(f\"Mode: {mode}, Backend: {backend}\")\n",
    "            if mode.startswith('dense'):\n",
    "                x0, y0 = u0_d, v0_d\n",
    "            else:\n",
    "                x0, y0 = u0_s, v0_s\n",
    "            if mode.endswith('CPU'):\n",
    "                x0, y0 = x0.cpu(), y0.cpu()\n",
    "                tensor_sketch = initialize_single_layer_sketch_modules(in_dim, out_dim, degree)[1].cpu()\n",
    "            else:\n",
    "                x0, y0 = x0.cuda(), y0.cuda()\n",
    "                tensor_sketch = initialize_single_layer_sketch_modules(in_dim, out_dim, degree)[1].cuda()\n",
    "            try:\n",
    "                tensor_sketch(x0)\n",
    "                print(\"Unit time: \", end=\"\")\n",
    "                %timeit tensor_sketch(x0)\n",
    "            except NotImplementedError as e:\n",
    "                print('Not Implemented')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d1d704-a949-43e8-9035-7f5943d2500d",
   "metadata": {},
   "source": [
    "### Errors\n",
    "\n",
    "Although we can see that the count sketch errors are large under this setup especially for degree=3, this is not an implementation mistake. The errors are large because you are sketching large square sparse matrices and you are comparing the approximated element-wise powers. This error metric is conceptually different to CountSketch's about which involves unsketching. In practice, we will not rely on this error bound explicitly.\n",
    "\n",
    "### Timing\n",
    "\n",
    "```\n",
    "TensorSketch: degree = 2\n",
    "Mode: sparse_CPU, Backend: Backends.PYTORCH_FFT\n",
    "Unit time: 12.1 ms ± 394 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "Mode: sparse_GPU, Backend: Backends.PYTORCH_FFT\n",
    "Unit time: 5.25 ms ± 141 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "TensorSketch: degree = 3\n",
    "Mode: sparse_CPU, Backend: Backends.PYTORCH_FFT\n",
    "Unit time: 19.1 ms ± 411 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "Mode: sparse_GPU, Backend: Backends.PYTORCH_FFT\n",
    "Unit time: 7.76 ms ± 154 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "```\n",
    "\n",
    "\n",
    "We see TensorSketch of degree=2 and 3 take up around 31.2ms/1.12ms=27.9x time than CountSketch of square sparse matrix of the same size and density. Thus, the real time bottleneck of sketching is on TensorSketch. There is a hope to optimize the process further by SFFT or unrolled TensorSketch for degree=2. But we may leave this to future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3944bb05-4965-4b9a-b88e-2c347c5fc9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
